# AIcarballo

[![LinkedIn](https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/acarballoalvarez/)

---

## ‚ö†Ô∏è Disclaimer (or: What Is This?)

Does the internet need *another* AI blog?  
**No.**

Does the world need *yet another* random person talking about AI?  
**Also no.**

So... what is this, then?

Think of this repo as a lifeboat in a vast ocean of noise, hype, and buzzwords. Every week, or whenever I feel like it, I'll share one or two things that I genuinely found **useful**, **thought-provoking**, or just plain **cool**: papers, podcasts, books, and...

**And the notebooks?**  
Those are mine.  
They're messy little experiments. Part learning journal, part sandbox, part "wait... what happens if I just do this?". Sometimes they'll follow a paper, sometimes they'll chase a random idea. But they're just a way to understand things better (or break them beautifully).

This isn't a newsletter, a course, or a sales funnel in disguise.  
It's just a personal attempt to filter signal from noise and maybe help someone else along the way.

You won't get smarter just by cloning the repo, but at least you'll drown in slightly better content (I hope).

---

## üß™ Notebooks

My own little experiments. Proceed with curiosity and low expectations.

| #   | Title                                      | Link                                                          | Topic | Description                                       |
|-----|--------------------------------------------|---------------------------------------------------------------|-------|---------------------------------------------------|
| 01  | Fast & Smart: Training and Tuning LightGBM | [üî¨](notebooks/lightgbm_model.ipynb)                          | ML    | LightGBM training, tuning, and comparison with XGBoost |

---

## üß† Papers & Reads

Papers that dig deep, articles that spark ideas, and the occasional read that invites confident nodding followed by total confusion.

| #   | Title                                                                 | Author(s)             | Link                                                        | Topic | Description |
|------|-----------------------------------------------------------------------|------------------------|-------------------------------------------------------------|-------|-------------|
| 01   | Will we run out of data? Limits of LLM scaling based on human-generated data | Villalobos et al. (2022) | [üîó](https://arxiv.org/abs/2211.04325)                    | LLMs  | A paper that basically says: yes, we might, especially when it comes to high-quality data. This is where LLMs start to hit a wall, not because of GPU limits, but because humans can only write so many Reddit posts before we run out of novelty. |

---

## üéß Podcasts

For when you want to learn something while pretending to do something useful, but mostly you're just dodging responsibilities with style.

| #   | Podcast | Guest           | Link                                                                 | Topic     | Description                                                  |
|-----|---------|------------------|----------------------------------------------------------------------|-----------|--------------------------------------------------------------|
| 01  | DOAC    | Geoffrey Hinton  | [üéß](https://open.spotify.com/episode/4X7dO0FuglP7yTm0kBAc50)        | AI Risks  | A necessary downer for AI enthusiasts. |

---

## üìò Books

Actual books. With pages. And ideas. Sometimes big, sometimes weird. Always worth the time.

| #   | Title                                                                                  | Author              | Link                                                                                   | Description |
|------|----------------------------------------------------------------------------------------|---------------------|----------------------------------------------------------------------------------------|-------------|
| 01   | Careless People: A Cautionary Tale of Power, Greed, and Lost Idealism                | Sarah Wynn-Williams | [üìò](https://www.amazon.es/Careless-People-Cautionary-Power-Idealism/dp/1250391237)   | Perfect for a summer read. The only thing the title doesn't mention is that it's actually about Facebook; everything else is true. |
| 02   | Supremacy: AI, ChatGPT, and the Race that Will Change the World                      | Parmy Olson         | [üìò](https://www.amazon.es/Supremacy-ChatGPT-Change-World-English-ebook/dp/B0CLJTMF84) | *Still reading. Could be genius, could be nonsense.* |

---

## ü§ù Contributing

Know something smart? Heard something wild? Send it my way. I can't promise eternal fame, but you might end up in a table.